{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iEpo_b24UZtp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/house_data.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter for only image_id 71 and 72\n",
        "df = df[df['image_id'].isin([71, 72])]\n",
        "\n",
        "# Separate features and target\n",
        "X_tab = df[['bed', 'bath', 'sqft']]  # you can add more columns\n",
        "y = df['price']\n"
      ],
      "metadata": {
        "id": "o9aYqvOdU2QN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_tab_scaled = scaler.fit_transform(X_tab)\n"
      ],
      "metadata": {
        "id": "-qNjhrcpVkX2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/imgs\"\n",
        "image_paths = [os.path.join(image_dir, f\"{img_id}.jpg\") for img_id in df['image_id']]\n",
        "\n",
        "images = []\n",
        "for path in image_paths:\n",
        "    img = load_img(path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    images.append(img_array)\n",
        "\n",
        "images = np.array(images)\n"
      ],
      "metadata": {
        "id": "azUAmXkVVmnt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_base = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
        "cnn_base.trainable = False  # freeze weights\n",
        "\n",
        "img_input = layers.Input(shape=(224, 224, 3))\n",
        "x = cnn_base(img_input)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "cnn_model = models.Model(inputs=img_input, outputs=x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atge0txnYF0A",
        "outputId": "f4bcc83a-ed44-4444-c2ca-81c1771ec467"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tab_input = layers.Input(shape=(X_tab_scaled.shape[1],))\n",
        "combined = layers.concatenate([cnn_model.output, tab_input])\n",
        "x = layers.Dense(64, activation='relu')(combined)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output = layers.Dense(1)(x)\n",
        "\n",
        "model = models.Model(inputs=[cnn_model.input, tab_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse')\n"
      ],
      "metadata": {
        "id": "iujNI6toYJC8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([images, X_tab_scaled], y, epochs=10, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpomLvwdYMXb",
        "outputId": "b89f678c-75cf-4428-b489-8b31eedc3858"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - loss: 47413116928.0000\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - loss: 47412854784.0000\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - loss: 47412740096.0000\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 47412596736.0000\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 47412412416.0000\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 47412195328.0000\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 47411916800.0000\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 47411855360.0000\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 47411474432.0000\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 47411159040.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9485c0a0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([images, X_tab_scaled])\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksSTSO35Z4Cg",
        "outputId": "4f98e75a-eb26-4275-d9fc-1b417bcdfb7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "MAE: 216995.09375\n",
            "RMSE: 217740.359437565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8A8AcXCnak4x"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_XoxiPjc2XY"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}